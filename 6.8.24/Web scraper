import requests
from bs4 import BeautifulSoup
import csv

def scrape_website(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    data = []

    for item in soup.find_all('div', class_='item'):
        title = item.find('h2').text.strip()
        description = item.find('p').text.strip()
        data.append([title, description])

    with open('data.csv', 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['Title', 'Description'])
        writer.writerows(data)

scrape_website('https://example.com')
